{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iKQrHajcdB5U"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nfv_fQ0OdB5b",
        "outputId": "272f3c22-3bab-47b6-b969-d9001830a267"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(['hello', 'how are you', 'goodbye'],\n",
              " ['ohe <eos>', 'kemon acho tumi <eos>', 'biday <eos>'],\n",
              " ['<sos> ohe', '<sos> kemon acho tumi', '<sos> biday'])"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "inputs = ['hello', 'how are you', 'goodbye']\n",
        "output = ['ohe', 'kemon acho tumi', 'biday']\n",
        "\n",
        "outputs=['{} <eos>'.format(x) for x in output ]\n",
        "outputs_i=['<sos> {}'.format(x) for x in output ]\n",
        "inputs,outputs,outputs_i"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BwC26Gp1dB5c",
        "outputId": "bc2aa9f8-7ec2-47a9-8451-d94d85ec7397"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(['ohe <eos>', 'kemon acho tumi <eos>', 'biday <eos>'],\n",
              " ['<sos> ohe', '<sos> kemon acho tumi', '<sos> biday'])"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "outputs,outputs_i"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7SUXG2EOdB5d"
      },
      "outputs": [],
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qGX5JFcndB5d",
        "outputId": "73c7a795-6166-49c6-ff8e-ed7e8c15c838"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total unique words in input: 5\n",
            "Length of longest sentence in input: 3\n",
            "Total unique words in output: 7\n",
            "Length of longest sentence in output: 5\n"
          ]
        }
      ],
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "\n",
        "MAX_NUM_WORDS=8\n",
        "\n",
        "input_tokenizer = Tokenizer(num_words=MAX_NUM_WORDS)\n",
        "input_tokenizer.fit_on_texts(inputs)\n",
        "\n",
        "\n",
        "#\n",
        "inputs_seq = input_tokenizer.texts_to_sequences(inputs)\n",
        "#\n",
        "\n",
        "#\n",
        "inputs_word2index = input_tokenizer.word_index\n",
        "\n",
        "# {a:1,go:40,here:100...........}\n",
        "\n",
        "print('Total unique words in input:', len(inputs_word2index))\n",
        "#\n",
        "\n",
        "\n",
        "inputs_numwords = len(inputs_word2index)+1\n",
        "#\n",
        "inputs_maxlen = max(len(s) for s in inputs_seq)\n",
        "print('Length of longest sentence in input:', inputs_maxlen)\n",
        "\n",
        "\n",
        "# related to output!!!!!!!!!!!!>>>>>>>>>>>>>>>>>>\n",
        "\n",
        "\n",
        "output_tokenizer = Tokenizer(num_words=MAX_NUM_WORDS, filters='')\n",
        "output_tokenizer.fit_on_texts(outputs_i + outputs)\n",
        "\n",
        "outputs_i_seq = output_tokenizer.texts_to_sequences(outputs_i)\n",
        "outputs_seq = output_tokenizer.texts_to_sequences(outputs)\n",
        "\n",
        "\n",
        "\n",
        "outputs_word2index = output_tokenizer.word_index\n",
        "print('Total unique words in output:', len(outputs_word2index))\n",
        "\n",
        "outputs_numwords = len(outputs_word2index)+1\n",
        "\n",
        "outputs_maxlen = max(len(s) for s in outputs_seq)+1\n",
        "print('Length of longest sentence in output:', outputs_maxlen)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W3Mk-RxLdB5e",
        "outputId": "8dd33a4e-312f-4664-dc1b-9e4a9a31d489"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'<sos>': 1,\n",
              " '<eos>': 2,\n",
              " 'ohe': 3,\n",
              " 'kemon': 4,\n",
              " 'acho': 5,\n",
              " 'tumi': 6,\n",
              " 'biday': 7}"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "outputs_word2index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FHA2_pejdB5e"
      },
      "outputs": [],
      "source": [
        "output_tokenizer = Tokenizer(num_words=MAX_NUM_WORDS, filters='')\n",
        "output_tokenizer.fit_on_texts(outputs_i + outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IHIFDS-7dB5f"
      },
      "outputs": [],
      "source": [
        "Oidx2wrd=output_tokenizer.index_word\n",
        "Owrd2idx={v:k for k,v in Oidx2wrd.items()}\n",
        "\n",
        "# Iidx2wrd=input_tokenizer.index_word\n",
        "# Iwrd2idx={v:k for k,v in Iidx2wrd.items()}\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XZp5a6I-dB5f",
        "outputId": "b71df374-fa28-4a71-f17a-1eb0b51f5915"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'hello': 1, 'how': 2, 'are': 3, 'you': 4, 'goodbye': 5}"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "input_tokenizer.word_index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h0KicbjPdB5g",
        "outputId": "775671f7-e750-444f-82aa-78ba15edcf28"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "encoder_input_sequences shape: (3, 3)\n",
            "decoder_inputs_sequences shape: (3, 5)\n",
            "decoder_output_sequences shape: (3, 5)\n"
          ]
        }
      ],
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "encoder_input_sequences = pad_sequences(inputs_seq, maxlen=inputs_maxlen)\n",
        "print('encoder_input_sequences shape:', encoder_input_sequences.shape)\n",
        "\n",
        "decoder_input_sequences = pad_sequences(outputs_i_seq, maxlen=outputs_maxlen, padding='post')\n",
        "print('decoder_inputs_sequences shape:', decoder_input_sequences.shape)\n",
        "\n",
        "decoder_output_sequences = pad_sequences(outputs_seq, maxlen=outputs_maxlen, padding='post')\n",
        "print('decoder_output_sequences shape:', decoder_output_sequences.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yvssV0pBdB5g",
        "outputId": "5012e392-2d57-4f0b-b5b4-a50345d06944"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0, 0, 1],\n",
              "       [2, 3, 4],\n",
              "       [0, 0, 5]], dtype=int32)"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "encoder_input_sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XRuPBXwEdB5g",
        "outputId": "e35c96d8-0d53-4b9c-e2f7-5b693ae82a68"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[1, 3, 0, 0, 0],\n",
              "       [1, 4, 5, 6, 0],\n",
              "       [1, 7, 0, 0, 0]], dtype=int32)"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "decoder_input_sequences"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1hJF-BDZdB5h"
      },
      "source": [
        "## the_model_cometh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LpKnNHpGdB5i"
      },
      "outputs": [],
      "source": [
        "NUM_SENTENCES = 4 # Use only the first 20,000 records.\n",
        "MAX_NUM_WORDS = 4 # Use 20,000 words for tokenizing\n",
        "MAX_SENT_LEN = 6\n",
        "\n",
        "EMBEDDING_SIZE = 5\n",
        "\n",
        "LSTM_NEURONS = 2\n",
        "\n",
        "BATCH_SIZE = 1\n",
        "EPOCHS = 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a4RPbT7UdB5i"
      },
      "outputs": [],
      "source": [
        "from keras.layers import Input, Embedding, LSTM, Dense\n",
        "\n",
        "encoder_embedding_layer = Embedding(\n",
        "    inputs_numwords, #super important\n",
        "    EMBEDDING_SIZE\n",
        "    )\n",
        "\n",
        "decoder_embedding_layer = Embedding(\n",
        "    outputs_numwords, #super important\n",
        "    EMBEDDING_SIZE\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "87TWXIugdB5j"
      },
      "outputs": [],
      "source": [
        "encoder_inputs = Input(shape=(inputs_maxlen,))\n",
        "encoder_inputs_emb = encoder_embedding_layer(encoder_inputs)\n",
        "encoder = LSTM(LSTM_NEURONS, return_state=True)\n",
        "encoder_outputs, h, c = encoder(encoder_inputs_emb)\n",
        "encoder_states = [h, c]\n",
        "\n",
        "decoder_inputs = Input(shape=(outputs_maxlen,))\n",
        "decoder_inputs_emb = decoder_embedding_layer(decoder_inputs)\n",
        "decoder = LSTM(LSTM_NEURONS, return_sequences=True, return_state=True)\n",
        "decoder_outputs, _, _ = decoder(decoder_inputs_emb, initial_state=encoder_states)\n",
        "\n",
        "output_dense_layer = Dense(outputs_numwords, activation='softmax')\n",
        "outputs = output_dense_layer(decoder_outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sM4mF-8udB5j",
        "outputId": "1fb27dc7-500a-4689-f24e-32bbc3262ab1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_3 (InputLayer)        [(None, 3)]                  0         []                            \n",
            "                                                                                                  \n",
            " input_4 (InputLayer)        [(None, 4)]                  0         []                            \n",
            "                                                                                                  \n",
            " embedding_2 (Embedding)     (None, 3, 5)                 30        ['input_3[0][0]']             \n",
            "                                                                                                  \n",
            " embedding_3 (Embedding)     (None, 4, 5)                 40        ['input_4[0][0]']             \n",
            "                                                                                                  \n",
            " lstm_2 (LSTM)               [(None, 2),                  64        ['embedding_2[0][0]']         \n",
            "                              (None, 2),                                                          \n",
            "                              (None, 2)]                                                          \n",
            "                                                                                                  \n",
            " lstm_3 (LSTM)               [(None, 4, 2),               64        ['embedding_3[0][0]',         \n",
            "                              (None, 2),                             'lstm_2[0][1]',              \n",
            "                              (None, 2)]                             'lstm_2[0][2]']              \n",
            "                                                                                                  \n",
            " dense_1 (Dense)             (None, 4, 8)                 24        ['lstm_3[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 222 (888.00 Byte)\n",
            "Trainable params: 222 (888.00 Byte)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "from keras.models import Model\n",
        "\n",
        "# defined [input] & output >>>>>>>>>>>>>>>\n",
        "model = Model([encoder_inputs, decoder_inputs], outputs)\n",
        "\n",
        "\n",
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "print(model.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fCmHl8gAdB5k"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "decoder_outputs_onehot  = tf.one_hot(decoder_output_sequences,\n",
        "\n",
        "depth=outputs_numwords #this param is important!!!\n",
        "\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZuWPtj7YeOSm",
        "outputId": "c8c736d2-f6df-4a0e-d5f3-2180ca1b6ab8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(3, 5, 8), dtype=float32, numpy=\n",
              " array([[[0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "         [0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "         [1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [1., 0., 0., 0., 0., 0., 0., 0.]],\n",
              " \n",
              "        [[0., 0., 0., 0., 1., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 1., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 1., 0.],\n",
              "         [0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "         [1., 0., 0., 0., 0., 0., 0., 0.]],\n",
              " \n",
              "        [[0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "         [1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [1., 0., 0., 0., 0., 0., 0., 0.]]], dtype=float32)>,\n",
              " <tf.Tensor: shape=(5, 8), dtype=float32, numpy=\n",
              " array([[0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "        [0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "        [1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [1., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)>,\n",
              " TensorShape([3, 5, 8]))"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "decoder_outputs_onehot,decoder_outputs_onehot[0],decoder_outputs_onehot.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9_8BCA0odB5k"
      },
      "outputs": [],
      "source": [
        "trn = model.fit([encoder_input_sequences, decoder_input_sequences],\n",
        "\n",
        "               decoder_outputs_onehot, epochs=1000\n",
        "               )\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bUn_JPSkdB5k"
      },
      "outputs": [],
      "source": [
        "# Iidx2wrd,Oidx2wrd,\n",
        "# output_tokenizer.word_index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hvV4FA05dB5k"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L8quU0HsdB5l"
      },
      "source": [
        "## THE_INFERENCE `is here boiis`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5MchajIldB5l",
        "outputId": "1644535f-ed67-4729-b3cd-23e843c458cc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[[2, 4, 1]]"
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "input_seq='how you hello'\n",
        "input_seq=input_tokenizer.texts_to_sequences([input_seq])\n",
        "input_seq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D4eaXxgfdB5l",
        "outputId": "03803c96-e5c8-415d-93f6-ff506116d85b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_3 (InputLayer)        [(None, 3)]               0         \n",
            "                                                                 \n",
            " embedding_2 (Embedding)     (None, 3, 5)              30        \n",
            "                                                                 \n",
            " lstm_2 (LSTM)               [(None, 2),               64        \n",
            "                              (None, 2),                         \n",
            "                              (None, 2)]                         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 94 (376.00 Byte)\n",
            "Trainable params: 94 (376.00 Byte)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "encoder_model = Model(encoder_inputs, encoder_states)\n",
        "print(encoder_model.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SPaxcbDhdB5l",
        "outputId": "1edab05a-78a1-4df2-af7e-2379c45b85f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_3\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_7 (InputLayer)        [(None, 1)]                  0         []                            \n",
            "                                                                                                  \n",
            " embedding_3 (Embedding)     multiple                     40        ['input_7[0][0]']             \n",
            "                                                                                                  \n",
            " input_5 (InputLayer)        [(None, 2)]                  0         []                            \n",
            "                                                                                                  \n",
            " input_6 (InputLayer)        [(None, 2)]                  0         []                            \n",
            "                                                                                                  \n",
            " lstm_3 (LSTM)               multiple                     64        ['embedding_3[1][0]',         \n",
            "                                                                     'input_5[0][0]',             \n",
            "                                                                     'input_6[0][0]']             \n",
            "                                                                                                  \n",
            " dense_1 (Dense)             multiple                     24        ['lstm_3[1][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 128 (512.00 Byte)\n",
            "Trainable params: 128 (512.00 Byte)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "decoder_input_h = Input(shape=(LSTM_NEURONS,))\n",
        "decoder_input_c = Input(shape=(LSTM_NEURONS,))\n",
        "decoder_input_states = [decoder_input_h, decoder_input_c]\n",
        "\n",
        "decoder_input_word = Input(shape=(1,))\n",
        "decoder_input_word_emb = decoder_embedding_layer(decoder_input_word)\n",
        "\n",
        "decoder_outputs, h, c = decoder(decoder_input_word_emb, initial_state=decoder_input_states)\n",
        "decoder_states = [h, c]\n",
        "\n",
        "outputs = output_dense_layer(decoder_outputs)\n",
        "decoder_model = Model([decoder_input_word]+decoder_input_states, [outputs]+decoder_states)\n",
        "print(decoder_model.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OTw5-qBIdB5m",
        "outputId": "e7e48e91-6aa4-49a7-f7ff-2638136a3964"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 433ms/step\n"
          ]
        }
      ],
      "source": [
        "states = encoder_model.predict(input_seq)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ni42I3W2dB5m",
        "outputId": "a2d42ec3-f5a9-4e92-808f-5ab0baafccfc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[array([[ 0.42293477, -0.48864064]], dtype=float32),\n",
              " array([[ 1.5939497, -1.2894503]], dtype=float32)]"
            ]
          },
          "execution_count": 67,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "states"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dSl79beBdB5m",
        "outputId": "a23f4430-d63a-4885-9aa4-50f7d63376df"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1, 2)"
            ]
          },
          "execution_count": 68,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sos= outputs_word2index['<sos>']\n",
        "eos = outputs_word2index['<eos>']\n",
        "sos,eos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SnUElBmKdB5n",
        "outputId": "f6ea1b35-0f79-4d70-bc4d-dc0e5c9e2614"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[1.]])"
            ]
          },
          "execution_count": 69,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "from numpy import zeros,argmax,argsort\n",
        "\n",
        "output_seq = zeros((1, 1))\n",
        "output_seq[0, 0] = sos\n",
        "output_seq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bt90nDpodB5n"
      },
      "outputs": [],
      "source": [
        "# after running all other\n",
        "# states = [h, c]\n",
        "# output_seq[0, 0] = idx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VgaQdUFHdB5n",
        "outputId": "19d48180-506f-4f7b-9a58-6fa447332b8e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 23ms/step\n"
          ]
        }
      ],
      "source": [
        "output_tokens, h, c = decoder_model.predict([output_seq]+states)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QlEVXpdkdB5o",
        "outputId": "c644cf7b-2c13-41df-e456-0f94c1468030"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((1, 1, 8),\n",
              " array([0.12396714, 0.04942955, 0.04175629, 0.03954481, 0.35189676,\n",
              "        0.23678899, 0.11158665, 0.04502974], dtype=float32),\n",
              " array([[[0.12396714, 0.04942955, 0.04175629, 0.03954481, 0.35189676,\n",
              "          0.23678899, 0.11158665, 0.04502974]]], dtype=float32))"
            ]
          },
          "execution_count": 71,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "output_tokens.shape ,output_tokens[0,0,:] , output_tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6eS8QhDkdB5o",
        "outputId": "19dae5c7-a2cf-4b4c-be4a-f0b34db1d3d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[ 0.75727046 -0.45094958]]\n",
            "\n",
            "\n",
            "\n",
            "[[ 1.0704943  -0.52320224]]\n",
            "{1: '<sos>', 2: '<eos>', 3: 'ohe', 4: 'kemon', 5: 'acho', 6: 'tumi', 7: 'biday'}\n"
          ]
        }
      ],
      "source": [
        "print(h)\n",
        "print('\\n\\n')\n",
        "print(c)\n",
        "print(Oidx2wrd)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6zA6HRMLdB5o"
      },
      "source": [
        "### how are you"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TW4A9h4p3ksd",
        "outputId": "f696e5dd-8007-4609-de4c-1d1783958dba"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "execution_count": 73,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "output_tokens\n",
        "idx = argmax(output_tokens)\n",
        "idx\n",
        "# word = Oidx2wrd[idx]\n",
        "# word,idx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9nl504ofdB5o",
        "outputId": "716f213c-9c56-4d4e-81ab-e3ee5671840b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "[[[0.13910478 0.04317958 0.0203299  0.0211306  0.4741164  0.19897586\n",
            "   0.06452952 0.03863336]]]\n",
            "kemon 4 [[[2 3 7 1 6 0 5 4]]]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "[[[0.025583   0.04447984 0.0407118  0.04767052 0.17517164 0.35222933\n",
            "   0.27496076 0.03919312]]]\n",
            "acho 5 [[[0 7 2 1 3 4 6 5]]]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "[[[0.01661182 0.03684727 0.07717348 0.07784576 0.08186343 0.2966622\n",
            "   0.37959674 0.0333993 ]]]\n",
            "tumi 6 [[[0 7 1 2 3 4 5 6]]]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "[[[0.07900012 0.01801891 0.49253038 0.19469264 0.02081157 0.05355823\n",
            "   0.12216033 0.01922783]]]\n",
            "<eos> 2 [[[1 7 4 5 0 6 3 2]]]\n"
          ]
        }
      ],
      "source": [
        "word='<sos>'\n",
        "input_seq='how are you'\n",
        "input_seq=input_tokenizer.texts_to_sequences([input_seq])\n",
        "states = encoder_model.predict(input_seq)\n",
        "while word!='<eos>':\n",
        "\n",
        "  output_tokens, h, c = decoder_model.predict([output_seq]+states)\n",
        "  print(output_tokens)\n",
        "  idx,srt = argmax(output_tokens,),np.argsort(output_tokens)\n",
        "\n",
        "  output_seq[0, 0] = idx\n",
        "  states=[h,c]\n",
        "  word = Oidx2wrd[idx]\n",
        "\n",
        "  print(word,idx,srt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Ax1__6ddB5p",
        "outputId": "08c991c6-078d-4873-c683-d8c9142c27d1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[[array([[1.]]), 0.0]]"
            ]
          },
          "execution_count": 75,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "decoder_input = np.zeros((1, 1))\n",
        "decoder_input[0, 0] = sos\n",
        "\n",
        "sequences = [[decoder_input, 0.0]]\n",
        "sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UdRl5np7dB5p"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "def BeamSearch(states,decoder_model,outputs_maxlen,beam_size=2):\n",
        "  max_len=outputs_maxlen+1\n",
        "  sos=Oidx2wrd[1]\n",
        "  decoder_input = np.zeros((1, 1))\n",
        "  decoder_input[0, 0] = 1\n",
        "\n",
        "  sequences = [[decoder_input, 0.0]]\n",
        "\n",
        "  ln=sequences[0][0][0]\n",
        "\n",
        "  neWeight={0:states}\n",
        "  ii=0\n",
        "  while len(ln) < max_len:\n",
        "      all_candidates = []\n",
        "\n",
        "\n",
        "\n",
        "      for i in range(len(sequences)):\n",
        "          seq, score = sequences[i]\n",
        "\n",
        "\n",
        "          decoder_input[0,0]=seq[0][-1]\n",
        "          if ii!=0:\n",
        "            current_states = states[i]\n",
        "          else:current_states = states\n",
        "          # print('input >>>',seq, decoder_input,)\n",
        "\n",
        "          probs, h, c = decoder_model.predict([decoder_input]+current_states)\n",
        "          word_preds = np.argsort(probs)[0][0][-beam_size:]\n",
        "\n",
        "\n",
        "          for w in word_preds:\n",
        "              candidate_seq = [\n",
        "                  np.concatenate([seq, np.array([[w]])], axis=1),\n",
        "\n",
        "                              score\n",
        "                              - np.log(probs[-1][-1][w])]\n",
        "              new_states = [h, c]\n",
        "              all_candidates.append((candidate_seq, new_states))\n",
        "      ii+=1\n",
        "      all_candidates.sort(key=lambda tup: tup[0][1])\n",
        "      sequences = [tup[0] for tup in all_candidates]\n",
        "      states = [tup[1] for tup in all_candidates]\n",
        "\n",
        "\n",
        "\n",
        "      ln=(sequences[0][0][0])\n",
        "  min_array = min(sequences, key=lambda x: x[1])\n",
        "  return min_array[0],sequences\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RLI1eLYJjwOI"
      },
      "source": [
        "{1: '<sos>', 2: '<eos>', 3: 'ohe', 4: 'kemon', 5: 'acho', 6: 'tumi', 7: 'biday'}\n",
        "({1: 'hello', 2: 'how', 3: 'are', 4: 'you', 5: 'goodbye'},"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YhcXLHGHPm00",
        "outputId": "e07da979-4b02-4f30-8222-6176b9a89135"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 125ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n"
          ]
        }
      ],
      "source": [
        "input_seq='how are you'\n",
        "input_seq=input_tokenizer.texts_to_sequences([input_seq])\n",
        "input_seq=[[2,3,4]]\n",
        "states = encoder_model.predict(input_seq)\n",
        "x,seq=BeamSearch(states,decoder_model ,outputs_maxlen,beam_size=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hKEWolX3dB5q",
        "outputId": "fbb47563-5e31-45d5-89ad-4fbf4c754c15"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[[array([[1., 4., 5., 6., 2., 2.]]), 4.441096544265747],\n",
              " [array([[1., 4., 6., 3., 0., 0.]]), 4.769274711608887],\n",
              " [array([[1., 4., 5., 5., 6., 2.]]), 4.927106618881226],\n",
              " [array([[1., 4., 5., 6., 3., 2.]]), 5.052044034004211],\n",
              " [array([[1., 4., 5., 6., 2., 3.]]), 5.230000138282776],\n",
              " [array([[1., 4., 6., 2., 2., 2.]]), 5.4529993534088135],\n",
              " [array([[1., 5., 4., 5., 6., 2.]]), 5.554852485656738],\n",
              " [array([[1., 4., 6., 3., 2., 0.]]), 5.582513928413391],\n",
              " [array([[1., 4., 6., 2., 3., 0.]]), 5.734493017196655],\n",
              " [array([[1., 5., 4., 6., 2., 2.]]), 5.746296763420105],\n",
              " [array([[1., 4., 5., 5., 2., 2.]]), 5.808568358421326],\n",
              " [array([[1., 4., 5., 5., 2., 6.]]), 5.848628520965576],\n",
              " [array([[1., 4., 5., 5., 6., 3.]]), 5.94578230381012],\n",
              " [array([[1., 4., 5., 6., 3., 0.]]), 6.069006562232971],\n",
              " [array([[1., 4., 6., 2., 3., 2.]]), 6.072152376174927],\n",
              " [array([[1., 4., 6., 2., 2., 3.]]), 6.125104665756226],\n",
              " [array([[1., 5., 5., 6., 2., 2.]]), 6.136052429676056],\n",
              " [array([[1., 5., 5., 6., 0., 0.]]), 6.190252631902695],\n",
              " [array([[1., 5., 4., 5., 5., 2.]]), 6.233413875102997],\n",
              " [array([[1., 5., 5., 6., 2., 0.]]), 6.402964770793915],\n",
              " [array([[1., 5., 5., 5., 2., 2.]]), 6.440853595733643],\n",
              " [array([[1., 4., 6., 3., 2., 2.]]), 6.443949341773987],\n",
              " [array([[1., 4., 6., 3., 0., 2.]]), 6.4735302329063416],\n",
              " [array([[1., 5., 4., 6., 3., 2.]]), 6.483932316303253],\n",
              " [array([[1., 5., 4., 6., 2., 3.]]), 6.511916279792786],\n",
              " [array([[1., 5., 4., 5., 6., 3.]]), 6.532501816749573],\n",
              " [array([[1., 5., 4., 6., 3., 0.]]), 6.592488169670105],\n",
              " [array([[1., 5., 5., 5., 3., 2.]]), 6.874683320522308],\n",
              " [array([[1., 5., 4., 5., 5., 3.]]), 6.972115397453308],\n",
              " [array([[1., 5., 5., 5., 2., 3.]]), 7.156654477119446],\n",
              " [array([[1., 5., 5., 6., 0., 2.]]), 7.34115469455719],\n",
              " [array([[1., 5., 5., 5., 3., 0.]]), 7.82352602481842]]"
            ]
          },
          "execution_count": 108,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "seq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-22yLGTDKMlY",
        "outputId": "2af5db92-9f92-4e9c-d15a-598e89d6b404"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[1., 4., 5., 6., 2., 2.]])"
            ]
          },
          "execution_count": 109,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# min_array = min(sequences, key=lambda x: x[1])\n",
        "# x=min_array[0]\n",
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hKFLbDK8KRM-",
        "outputId": "a859d6ad-9edd-4d5e-eae0-75bd457f5b0a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.0 <sos>\n",
            "4.0 kemon\n",
            "5.0 acho\n",
            "6.0 tumi\n",
            "2.0 <eos>\n",
            "2.0 <eos>\n"
          ]
        }
      ],
      "source": [
        "\n",
        "for i in x[0]:\n",
        "    print(i,Oidx2wrd[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yAzmkZwoOuvD"
      },
      "outputs": [],
      "source": [
        "start_seq = np.array([[1]])\n",
        "initial_states = [states] + [np.zeros((1, LSTM_NEURONS))] * 2  #\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kclojHSbyt-L"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A7QYm8ercZZI"
      },
      "source": [
        "# TRANSFORMERS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eYJcsh5xcemY",
        "outputId": "abc7f4d6-09ab-4997-876b-d8d642619b07"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(3, 3)"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text_pairs=[]\n",
        "# [('He turned to look Langdon in the eye.',\n",
        "#   '[start] সে ঘুরে ল্যাংডনের চোখের দিকে তাকায়। [end]'),\n",
        "\n",
        "en_lst = ['hello', 'how are you', 'goodbye']\n",
        "ben_lst = ['ohe', 'kemon acho tumi', 'biday']\n",
        "len(ben_lst),len(en_lst)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5YIAYcvYc7oA",
        "outputId": "34d21bf5-ca03-414d-eccc-45c0c0235ba0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('hello', '[start] ohe [end]'),\n",
              " ('how are you', '[start] kemon acho tumi [end]'),\n",
              " ('goodbye', '[start] biday [end]')]"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text_pairs=[]\n",
        "cnt=0\n",
        "for eng,ben in zip(en_lst,ben_lst):\n",
        "  if len(ben.split())>50:\n",
        "    continue\n",
        "  ben = \"[start] \" + ben + \" [end]\"\n",
        "  text_pairs.append((eng,ben))\n",
        "  cnt+=1\n",
        "  if cnt>=(2753069//3):breaka\n",
        "len(text_pairs)\n",
        "\n",
        "text_pairs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0SlcjVM6c914",
        "outputId": "e1254c6e-5e21-4b28-8c4e-0b9b438ea769"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "hello, world! how are you doing? 12/3\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import re\n",
        "\n",
        "# Define the characters to keep\n",
        "keep_chars = \".,?!| / -\"\n",
        "\n",
        "def custom_standardization(input_string):\n",
        "    # Convert to lowercase\n",
        "    lowercase = tf.strings.lower(input_string)\n",
        "\n",
        "    # Remove non-alphabetic characters, except for those in the keep_chars set and digits\n",
        "    stripped = tf.strings.regex_replace(lowercase, \"[^a-z0-9\" + re.escape(keep_chars) + \"]\", \"\")\n",
        "\n",
        "    return stripped\n",
        "\n",
        "# Example usage:\n",
        "strip_chars = \"!@#$%^&*()_-+=[]{}|;:',.<>?/\"\n",
        "input_text = tf.constant(\"Hello, World! How are you doing? 12/3\")\n",
        "processed_text = custom_standardization(input_text)\n",
        "\n",
        "print(processed_text.numpy().decode(\"utf-8\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7EqsQIE7dkFM"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "random.shuffle(text_pairs)\n",
        "num_val_samples = int(0* len(text_pairs))\n",
        "num_train_samples = len(text_pairs) - 2 * num_val_samples\n",
        "train_pairs = text_pairs[:num_train_samples]\n",
        "val_pairs = text_pairs[num_train_samples:num_train_samples + num_val_samples]\n",
        "test_pairs = text_pairs[num_train_samples + num_val_samples:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M9aUF2CLdnkt",
        "outputId": "9f9aebb9-d3a8-4cfe-b144-acddced9699d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "val_pairs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b3lRlyMJdD1P"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import string\n",
        "import re\n",
        "from tensorflow.keras import layers\n",
        "sequence_length=5\n",
        "max_token=8\n",
        "source_vectorization = layers.TextVectorization(\n",
        "  max_tokens=max_token,\n",
        "  output_mode=\"int\",\n",
        "  output_sequence_length=sequence_length,\n",
        "  standardize=custom_standardization\n",
        ")\n",
        "target_vectorization = layers.TextVectorization(\n",
        "  max_tokens=max_token,\n",
        "  output_mode=\"int\",\n",
        "  output_sequence_length=sequence_length + 1,\n",
        "\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SFv9nOHddUMt",
        "outputId": "5de99724-ad1b-4c3c-ab42-c146402338a0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(['goodbye', 'how are you', 'hello'],\n",
              " ['[start] biday [end]', '[start] kemon acho tumi [end]', '[start] ohe [end]'])"
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "train_eng_texts = [pair[0] for pair in train_pairs]\n",
        "train_ben_texts = [pair[1] for pair in train_pairs]\n",
        "\n",
        "train_eng_texts,train_ben_texts\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "STGacpi8dumE"
      },
      "outputs": [],
      "source": [
        "def createVector(pairs,vectorztn):\n",
        "  batch_size = 10000  # Adjust the batch size based on your available memory\n",
        "  num_batches = len(pairs) // batch_size + 1\n",
        "\n",
        "  for i in range(num_batches):\n",
        "      start_idx = i * batch_size\n",
        "      end_idx = min((i + 1) * batch_size, len(pairs))\n",
        "      batch_texts = pairs[start_idx:end_idx]\n",
        "      vectorztn.adapt(batch_texts)\n",
        "      # target_vectorization.adapt(batch_ben_texts)  # Uncomment if needed\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FBQqkCCldwTF"
      },
      "outputs": [],
      "source": [
        "createVector(train_eng_texts,source_vectorization)\n",
        "createVector(train_ben_texts,target_vectorization)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u80B2yIZd30N",
        "outputId": "fd31cc8e-9105-4a5c-9ed6-c6aa3e3cebd3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vocabulary: ['', '[UNK]', 'you', 'how', 'hello', 'goodbye', 'are']\n",
            "Max Tokens: 8\n",
            "Output Sequence Length: 5\n",
            "Output Mode: int\n",
            "Standardization: <function custom_standardization at 0x7f648e585f30>\n"
          ]
        }
      ],
      "source": [
        "\n",
        "vocabulary = source_vectorization.get_vocabulary()\n",
        "\n",
        "# Access other relevant information\n",
        "max_tokens = source_vectorization.get_config()['max_tokens']\n",
        "output_sequence_length = source_vectorization.get_config()['output_sequence_length']\n",
        "output_mode = source_vectorization.get_config()['output_mode']\n",
        "standardization = source_vectorization.get_config()['standardize']\n",
        "\n",
        "# Print or inspect the information\n",
        "print(\"Vocabulary:\", vocabulary)\n",
        "print(\"Max Tokens:\", max_tokens)\n",
        "print(\"Output Sequence Length:\", output_sequence_length)\n",
        "print(\"Output Mode:\", output_mode)\n",
        "print(\"Standardization:\", standardization)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m8EhvqVpeEi8"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Assuming source_vectorization and target_vectorization are TextVectorization layers\n",
        "\n",
        "batch_size =1\n",
        "\n",
        "def format_dataset(eng, ben):\n",
        "    eng = source_vectorization(eng)\n",
        "    ben = target_vectorization(ben)\n",
        "    # Ensure ben has the expected shape before slicing\n",
        "    # ben = tf.reshape(ben, [tf.shape(ben)[0], -1])  # Reshape to 2D\n",
        "    return {\"eng\": eng, \"ben\": ben[:, :-1]}, ben[:, 1:]\n",
        "\n",
        "def make_dataset(pairs):\n",
        "    eng_texts, ben_texts = zip(*pairs)\n",
        "    eng_texts = list(eng_texts)\n",
        "    ben_texts = list(ben_texts)\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((eng_texts, ben_texts))\n",
        "    dataset = dataset.batch(batch_size)\n",
        "    dataset = dataset.map(format_dataset, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "    return dataset.shuffle(2048).prefetch(16).cache()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fr7fqMGKeIkD"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "train_ds = make_dataset(train_pairs)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aFf42oNNeMaT"
      },
      "source": [
        "## ENCODER"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iVWrtje7eOPX"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "class TransformerEncoder(layers.Layer):\n",
        "    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.embed_dim = embed_dim\n",
        "        self.dense_dim = dense_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.attention = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embed_dim)\n",
        "        self.dense_proj = keras.Sequential(\n",
        "            [layers.Dense(dense_dim, activation=\"relu\"),\n",
        "             layers.Dense(embed_dim),]\n",
        "        )\n",
        "        self.layernorm_1 = layers.LayerNormalization()\n",
        "        self.layernorm_2 = layers.LayerNormalization()\n",
        "\n",
        "    def call(self, inputs, mask=None):\n",
        "        if mask is not None:\n",
        "            mask = mask[:, tf.newaxis, :]\n",
        "        attention_output = self.attention(\n",
        "            inputs, inputs, attention_mask=mask)\n",
        "        proj_input = self.layernorm_1(inputs + attention_output)\n",
        "        proj_output = self.dense_proj(proj_input)\n",
        "        return self.layernorm_2(proj_input + proj_output)\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update({\n",
        "            \"embed_dim\": self.embed_dim,\n",
        "            \"num_heads\": self.num_heads,\n",
        "            \"dense_dim\": self.dense_dim,\n",
        "        })\n",
        "        return config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "camnoY_peQzk"
      },
      "outputs": [],
      "source": [
        "class TransformerDecoder(layers.Layer):\n",
        "    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.embed_dim = embed_dim\n",
        "        self.dense_dim = dense_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.attention_1 = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embed_dim)\n",
        "        self.attention_2 = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embed_dim)\n",
        "        self.dense_proj = keras.Sequential(\n",
        "            [layers.Dense(dense_dim, activation=\"relu\"),\n",
        "             layers.Dense(embed_dim),]\n",
        "        )\n",
        "        self.layernorm_1 = layers.LayerNormalization()\n",
        "        self.layernorm_2 = layers.LayerNormalization()\n",
        "        self.layernorm_3 = layers.LayerNormalization()\n",
        "        self.supports_masking = True\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update({\n",
        "            \"embed_dim\": self.embed_dim,\n",
        "            \"num_heads\": self.num_heads,\n",
        "            \"dense_dim\": self.dense_dim,\n",
        "        })\n",
        "        return config\n",
        "\n",
        "    def get_causal_attention_mask(self, inputs):\n",
        "        input_shape = tf.shape(inputs)\n",
        "        batch_size, sequence_length = input_shape[0], input_shape[1]\n",
        "        i = tf.range(sequence_length)[:, tf.newaxis]\n",
        "        j = tf.range(sequence_length)\n",
        "        mask = tf.cast(i >= j, dtype=\"int32\")\n",
        "        mask = tf.reshape(mask, (1, input_shape[1], input_shape[1]))\n",
        "        mult = tf.concat(\n",
        "            [tf.expand_dims(batch_size, -1),\n",
        "             tf.constant([1, 1], dtype=tf.int32)], axis=0)\n",
        "        return tf.tile(mask, mult)\n",
        "\n",
        "    def call(self, inputs, encoder_outputs, mask=None):\n",
        "        causal_mask = self.get_causal_attention_mask(inputs)\n",
        "        if mask is not None:\n",
        "            padding_mask = tf.cast(\n",
        "                mask[:, tf.newaxis, :], dtype=\"int32\")\n",
        "            padding_mask = tf.minimum(padding_mask, causal_mask)\n",
        "        else:\n",
        "            padding_mask = mask\n",
        "        attention_output_1 = self.attention_1(\n",
        "            query=inputs,\n",
        "            value=inputs,\n",
        "            key=inputs,\n",
        "            attention_mask=causal_mask)\n",
        "        attention_output_1 = self.layernorm_1(inputs + attention_output_1)\n",
        "        attention_output_2 = self.attention_2(\n",
        "            query=attention_output_1,\n",
        "            value=encoder_outputs,\n",
        "            key=encoder_outputs,\n",
        "            attention_mask=padding_mask,\n",
        "        )\n",
        "        attention_output_2 = self.layernorm_2(\n",
        "            attention_output_1 + attention_output_2)\n",
        "        proj_output = self.dense_proj(attention_output_2)\n",
        "        return self.layernorm_3(attention_output_2 + proj_output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7cSe3DDjeULb"
      },
      "outputs": [],
      "source": [
        "class PositionalEmbedding(layers.Layer):\n",
        "    def __init__(self, sequence_length, input_dim, output_dim, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.token_embeddings = layers.Embedding(\n",
        "            input_dim=input_dim, output_dim=output_dim)\n",
        "        self.position_embeddings = layers.Embedding(\n",
        "            input_dim=sequence_length, output_dim=output_dim)\n",
        "        self.sequence_length = sequence_length\n",
        "        self.input_dim = input_dim\n",
        "        self.output_dim = output_dim\n",
        "\n",
        "    def call(self, inputs):\n",
        "        length = tf.shape(inputs)[-1]\n",
        "        positions = tf.range(start=0, limit=length, delta=1)\n",
        "        embedded_tokens = self.token_embeddings(inputs)\n",
        "        embedded_positions = self.position_embeddings(positions)\n",
        "        return embedded_tokens + embedded_positions\n",
        "\n",
        "    def compute_mask(self, inputs, mask=None):\n",
        "        return tf.math.not_equal(inputs, 0)\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super(PositionalEmbedding, self).get_config()\n",
        "        config.update({\n",
        "            \"output_dim\": self.output_dim,\n",
        "            \"sequence_length\": self.sequence_length,\n",
        "            \"input_dim\": self.input_dim,\n",
        "        })\n",
        "        return config"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wyuX7OtreXNG"
      },
      "source": [
        "## THY MODEL COMETH"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yvswsLiSei7l",
        "outputId": "49a9e5c0-b623-4391-c2ab-da4e847ef9a6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sequence_length"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 634
        },
        "id": "C7Wv2FkEeY4-",
        "outputId": "c675a525-ce89-4fbd-d078-b57bd61f0b84"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "Exception encountered when calling layer \"transformer_decoder_4\" (type TransformerDecoder).\n\nin user code:\n\n    File \"<ipython-input-21-6a8ecb8b5582>\", line 64, in call  *\n        return self.layernorm_3(attention_output_2 + proj_output)\n\n    ValueError: Dimensions must be equal, but are 7 and 2 for '{{node transformer_decoder_4/add_2}} = AddV2[T=DT_FLOAT](transformer_decoder_4/layer_normalization_23/add, transformer_decoder_4/sequential_9/dense_23/BiasAdd)' with input shapes: [?,?,7], [?,?,2].\n\n\nCall arguments received by layer \"transformer_decoder_4\" (type TransformerDecoder):\n  • inputs=tf.Tensor(shape=(None, None, 7), dtype=float32)\n  • encoder_outputs=tf.Tensor(shape=(None, None, 7), dtype=float32)\n  • mask=tf.Tensor(shape=(None, None), dtype=bool)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-82-6d6edbc08921>\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mdecoder_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"int64\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"ben\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPositionalEmbedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membed_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTransformerDecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.35\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mdecoder_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"softmax\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/__autograph_generated_filexcg9bfm_.py\u001b[0m in \u001b[0;36mtf__call\u001b[0;34m(self, inputs, encoder_outputs, mask)\u001b[0m\n\u001b[1;32m     34\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m                     \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayernorm_3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_output_2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproj_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling layer \"transformer_decoder_4\" (type TransformerDecoder).\n\nin user code:\n\n    File \"<ipython-input-21-6a8ecb8b5582>\", line 64, in call  *\n        return self.layernorm_3(attention_output_2 + proj_output)\n\n    ValueError: Dimensions must be equal, but are 7 and 2 for '{{node transformer_decoder_4/add_2}} = AddV2[T=DT_FLOAT](transformer_decoder_4/layer_normalization_23/add, transformer_decoder_4/sequential_9/dense_23/BiasAdd)' with input shapes: [?,?,7], [?,?,2].\n\n\nCall arguments received by layer \"transformer_decoder_4\" (type TransformerDecoder):\n  • inputs=tf.Tensor(shape=(None, None, 7), dtype=float32)\n  • encoder_outputs=tf.Tensor(shape=(None, None, 7), dtype=float32)\n  • mask=tf.Tensor(shape=(None, None), dtype=bool)"
          ]
        }
      ],
      "source": [
        "embed_dim = 7\n",
        "dense_dim = 5\n",
        "num_heads = 3\n",
        "vocab_size=max_token\n",
        "encoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"eng\")\n",
        "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(encoder_inputs)\n",
        "encoder_outputs = TransformerEncoder(embed_dim, dense_dim, num_heads)(x)\n",
        "\n",
        "decoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"ben\")\n",
        "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(decoder_inputs)\n",
        "x = TransformerDecoder(2, 1, 1)(x, encoder_outputs)\n",
        "x = layers.Dropout(0.35)(x)\n",
        "decoder_outputs = layers.Dense(vocab_size, activation=\"softmax\")(x)\n",
        "transformer = keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KAG50rM_enrv"
      },
      "outputs": [],
      "source": [
        "transformer.compile(\n",
        "    optimizer=\"rmsprop\",\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"])\n",
        "transformer.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lrQot0egepjo",
        "outputId": "92d6464d-256c-4bdf-e133-2cc515e05298"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.5007 - accuracy: 0.9091\n",
            "Epoch 2/10\n",
            "3/3 [==============================] - 0s 45ms/step - loss: 0.5179 - accuracy: 0.8182\n",
            "Epoch 3/10\n",
            "3/3 [==============================] - 0s 41ms/step - loss: 0.6332 - accuracy: 0.7273\n",
            "Epoch 4/10\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.4246 - accuracy: 0.9091\n",
            "Epoch 5/10\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.4528 - accuracy: 0.9091\n",
            "Epoch 6/10\n",
            "3/3 [==============================] - 0s 51ms/step - loss: 0.5622 - accuracy: 1.0000\n",
            "Epoch 7/10\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 0.4533 - accuracy: 0.8182\n",
            "Epoch 8/10\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.3698 - accuracy: 0.9091\n",
            "Epoch 9/10\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.7393 - accuracy: 0.6364\n",
            "Epoch 10/10\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.5825 - accuracy: 0.9091\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7f648ce6b430>"
            ]
          },
          "execution_count": 84,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "transformer.fit(train_ds, epochs=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mh2rSGQCe_cb",
        "outputId": "f50a95e8-859c-4e79-ff93-2d2855ea9a47"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['goodbye', 'how are you', 'hello']\n",
            "-\n",
            "hello\n",
            "tf.Tensor(\n",
            "[[[0.06063902 0.03009121 0.09070338 0.00791099 0.04171789 0.662482\n",
            "   0.04821628 0.05823914]\n",
            "  [0.01118857 0.14030212 0.08620804 0.17818864 0.29932112 0.03127718\n",
            "   0.01848049 0.23503381]\n",
            "  [0.17399217 0.12136269 0.09399368 0.0275175  0.37002128 0.0613298\n",
            "   0.00872514 0.1430578 ]\n",
            "  [0.10372666 0.06721615 0.05658646 0.06974798 0.20958583 0.02104655\n",
            "   0.00719189 0.4648984 ]\n",
            "  [0.18730782 0.10450784 0.11655206 0.01258979 0.34783188 0.1367449\n",
            "   0.0073265  0.08713917]]], shape=(1, 5, 8), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[[0.06063902 0.03009121 0.09070338 0.00791099 0.04171789 0.662482\n",
            "   0.04821628 0.05823914]\n",
            "  [0.00484515 0.02480874 0.00683273 0.847514   0.01916827 0.0024\n",
            "   0.05261295 0.04181822]\n",
            "  [0.25430652 0.10462575 0.03649896 0.1765975  0.12523805 0.0108721\n",
            "   0.02454423 0.26731682]\n",
            "  [0.10809826 0.05933811 0.01850955 0.3508915  0.05341465 0.00351128\n",
            "   0.02019378 0.38604286]\n",
            "  [0.37622908 0.1016807  0.05361092 0.0454697  0.21175626 0.02333042\n",
            "   0.00934285 0.17858012]]], shape=(1, 5, 8), dtype=float32)\n",
            "[start] ohe end\n",
            "-\n",
            "how are you\n",
            "tf.Tensor(\n",
            "[[[0.07658511 0.0352147  0.02179243 0.2477794  0.00823214 0.05926653\n",
            "   0.49819082 0.05293887]\n",
            "  [0.0093407  0.05323768 0.01067168 0.7740558  0.02415621 0.00262333\n",
            "   0.05706277 0.06885179]\n",
            "  [0.1624137  0.09613319 0.0222494  0.4705666  0.05470871 0.00829288\n",
            "   0.0777925  0.10784297]\n",
            "  [0.07077796 0.04458754 0.01039993 0.6595052  0.02113233 0.00294723\n",
            "   0.05857309 0.13207673]\n",
            "  [0.32979554 0.12961969 0.03279537 0.2534607  0.10701628 0.01351751\n",
            "   0.04637684 0.08741809]]], shape=(1, 5, 8), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[[0.07658511 0.0352147  0.02179243 0.2477794  0.00823214 0.05926653\n",
            "   0.49819082 0.05293887]\n",
            "  [0.06541537 0.6321476  0.09593479 0.0423787  0.04462723 0.03127981\n",
            "   0.03180772 0.05640864]\n",
            "  [0.16039808 0.11625522 0.02815635 0.34764802 0.06603676 0.00746552\n",
            "   0.05038769 0.22365232]\n",
            "  [0.0696914  0.06730624 0.01470914 0.5434039  0.0303783  0.00284675\n",
            "   0.03965431 0.23200989]\n",
            "  [0.26435724 0.1561758  0.04135635 0.16385205 0.1165138  0.01072004\n",
            "   0.02597603 0.22104867]]], shape=(1, 5, 8), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[[0.07658511 0.0352147  0.02179243 0.2477794  0.00823214 0.05926653\n",
            "   0.49819082 0.05293887]\n",
            "  [0.06541537 0.6321476  0.09593479 0.0423787  0.04462723 0.03127981\n",
            "   0.03180772 0.05640864]\n",
            "  [0.05729974 0.13187088 0.07876381 0.08852951 0.43562466 0.02754637\n",
            "   0.0073306  0.17303446]\n",
            "  [0.07663884 0.065263   0.01731753 0.46369305 0.0570837  0.00305235\n",
            "   0.02366915 0.2932823 ]\n",
            "  [0.23394664 0.19264759 0.07086788 0.06128187 0.2922594  0.02691241\n",
            "   0.01246396 0.10962026]]], shape=(1, 5, 8), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[[0.07658511 0.0352147  0.02179243 0.2477794  0.00823214 0.05926653\n",
            "   0.49819082 0.05293887]\n",
            "  [0.06541537 0.6321476  0.09593479 0.0423787  0.04462723 0.03127981\n",
            "   0.03180772 0.05640864]\n",
            "  [0.05729974 0.13187088 0.07876381 0.08852951 0.43562466 0.02754637\n",
            "   0.0073306  0.17303446]\n",
            "  [0.00689665 0.01403635 0.00563437 0.86808515 0.02039398 0.00259922\n",
            "   0.04006812 0.04228618]\n",
            "  [0.34269068 0.1069948  0.04868424 0.0849705  0.2514081  0.02122595\n",
            "   0.01330106 0.13072467]]], shape=(1, 5, 8), dtype=float32)\n",
            "[start] kemon [UNK] tumi end\n",
            "-\n",
            "how are you\n",
            "tf.Tensor(\n",
            "[[[0.07658511 0.0352147  0.02179243 0.2477794  0.00823214 0.05926653\n",
            "   0.49819082 0.05293887]\n",
            "  [0.0093407  0.05323768 0.01067168 0.7740558  0.02415621 0.00262333\n",
            "   0.05706277 0.06885179]\n",
            "  [0.1624137  0.09613319 0.0222494  0.4705666  0.05470871 0.00829288\n",
            "   0.0777925  0.10784297]\n",
            "  [0.07077796 0.04458754 0.01039993 0.6595052  0.02113233 0.00294723\n",
            "   0.05857309 0.13207673]\n",
            "  [0.32979554 0.12961969 0.03279537 0.2534607  0.10701628 0.01351751\n",
            "   0.04637684 0.08741809]]], shape=(1, 5, 8), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[[0.07658511 0.0352147  0.02179243 0.2477794  0.00823214 0.05926653\n",
            "   0.49819082 0.05293887]\n",
            "  [0.06541537 0.6321476  0.09593479 0.0423787  0.04462723 0.03127981\n",
            "   0.03180772 0.05640864]\n",
            "  [0.16039808 0.11625522 0.02815635 0.34764802 0.06603676 0.00746552\n",
            "   0.05038769 0.22365232]\n",
            "  [0.0696914  0.06730624 0.01470914 0.5434039  0.0303783  0.00284675\n",
            "   0.03965431 0.23200989]\n",
            "  [0.26435724 0.1561758  0.04135635 0.16385205 0.1165138  0.01072004\n",
            "   0.02597603 0.22104867]]], shape=(1, 5, 8), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[[0.07658511 0.0352147  0.02179243 0.2477794  0.00823214 0.05926653\n",
            "   0.49819082 0.05293887]\n",
            "  [0.06541537 0.6321476  0.09593479 0.0423787  0.04462723 0.03127981\n",
            "   0.03180772 0.05640864]\n",
            "  [0.05729974 0.13187088 0.07876381 0.08852951 0.43562466 0.02754637\n",
            "   0.0073306  0.17303446]\n",
            "  [0.07663884 0.065263   0.01731753 0.46369305 0.0570837  0.00305235\n",
            "   0.02366915 0.2932823 ]\n",
            "  [0.23394664 0.19264759 0.07086788 0.06128187 0.2922594  0.02691241\n",
            "   0.01246396 0.10962026]]], shape=(1, 5, 8), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[[0.07658511 0.0352147  0.02179243 0.2477794  0.00823214 0.05926653\n",
            "   0.49819082 0.05293887]\n",
            "  [0.06541537 0.6321476  0.09593479 0.0423787  0.04462723 0.03127981\n",
            "   0.03180772 0.05640864]\n",
            "  [0.05729974 0.13187088 0.07876381 0.08852951 0.43562466 0.02754637\n",
            "   0.0073306  0.17303446]\n",
            "  [0.00689665 0.01403635 0.00563437 0.86808515 0.02039398 0.00259922\n",
            "   0.04006812 0.04228618]\n",
            "  [0.34269068 0.1069948  0.04868424 0.0849705  0.2514081  0.02122595\n",
            "   0.01330106 0.13072467]]], shape=(1, 5, 8), dtype=float32)\n",
            "[start] kemon [UNK] tumi end\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "spa_vocab = target_vectorization.get_vocabulary()\n",
        "spa_index_lookup = dict(zip(range(len(spa_vocab)), spa_vocab))\n",
        "max_decoded_sentence_length = 5\n",
        "\n",
        "def decode_sequence(input_sentence):\n",
        "    tokenized_input_sentence = source_vectorization([input_sentence])\n",
        "    decoded_sentence = \"[start]\"\n",
        "    for i in range(max_decoded_sentence_length):\n",
        "        tokenized_target_sentence = target_vectorization(\n",
        "            [decoded_sentence])[:, :-1]\n",
        "        predictions = transformer(\n",
        "            [tokenized_input_sentence, tokenized_target_sentence])\n",
        "        print(predictions)\n",
        "        sampled_token_index = np.argmax(predictions[0, i, :])\n",
        "        sampled_token = spa_index_lookup[sampled_token_index]\n",
        "        decoded_sentence += \" \" + sampled_token\n",
        "        if sampled_token == \"end\":\n",
        "            break\n",
        "    return decoded_sentence\n",
        "\n",
        "\n",
        "test_pairs=train_pairs\n",
        "\n",
        "test_eng_texts = [pair[0] for pair in test_pairs]\n",
        "print(test_eng_texts)\n",
        "\n",
        "# >>>>>>>>>>>>>>>>>\n",
        "input_sentence = random.choice(test_eng_texts)\n",
        "print(\"-\")\n",
        "print(input_sentence)\n",
        "print(decode_sequence(input_sentence))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8wLU9dtLgOeY"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}